{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cse6740.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "Data source: https://www.kaggle.com/datasets/foklacu/ukraine-war-tweets-dataset-65-days?resource=download\n",
        "\n",
        "Download the archieve.zip file and unzip it.\n",
        "\n",
        "## Initial clean\n",
        "Choose several key features \"username\"/\"date\" and saved as a new dataset."
      ],
      "metadata": {
        "id": "aTxcvzYmtZC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "path = r\"./content/drive/MyDrive/cse6740/archive\" # use your path\n",
        "all_files = os.listdir(path)\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(path + '/' + filename, index_col=None, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\n",
        "\n",
        "df = pd.DataFrame(frame, columns = ['date','content', 'user', 'replyCount','retweetCount','likeCount','quoteCount'])\n",
        "user_df = df['user'].map(eval).apply(pd.Series)\n",
        "cleaned_df = pd.DataFrame(user_df, columns = ['username','displayname','followersCount','friendsCount','statusesCount','favouritesCount','listedCount','mediaCount','location'])\n",
        "cleaned_df = cleaned_df.join(df.drop(columns = 'user'))\n",
        "\n",
        "cleaned_df.to_csv('./content/drive/MyDrive/cse6740/cleaned_df.csv')"
      ],
      "metadata": {
        "id": "VpUwgEpFODky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sentimental analysis\n",
        "\n",
        "https://github.com/pysentimiento/pysentimiento"
      ],
      "metadata": {
        "id": "1c_bWMDjuLFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install pysentimiento\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/cse6740/cleaned_df.csv')\n",
        "\n",
        "tweets = df['content'].tolist()\n",
        "from pysentimiento.preprocessing import preprocess_tweet\n",
        "tws_clean = []\n",
        "\n",
        "for tw in tweets:\n",
        "  tws_clean.append(preprocess_tweet(tw))\n",
        "\n",
        "from pysentimiento import create_analyzer\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "\n",
        "for tw in tws_clean:\n",
        "  res.append(analyzer.predict(tw).output)\n",
        "\n",
        "new_df = df\n",
        "new_df['res'] = res\n",
        "\n",
        "new_df.to_json('/content/drive/MyDrive/cse6740/labeled_sa_df.json')"
      ],
      "metadata": {
        "id": "SGX1KAZUQLip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geolocation labeling\n",
        "\n",
        "A better way to get the geographical information is to use geocode lib.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0UKTfgUZu-7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "location = df['location'].tolist()\n",
        "longitude = []\n",
        "latitude = []\n",
        "\n",
        "for i in range(len(location)):\n",
        "  loc = location[i]\n",
        "  if str(loc) != 'nan':\n",
        "    try:\n",
        "      geolo = geolocator.geocode(loc)\n",
        "      if geolo:\n",
        "        longitude.append(str(geolo.longitude))\n",
        "        latitude.append(str(geolo.latitude))\n",
        "      else:\n",
        "        longitude.append(\"nan\")\n",
        "        latitude.append(\"nan\")\n",
        "    except:\n",
        "      longitude.append(\"nan\")\n",
        "      latitude.append(\"nan\")\n",
        "\n",
        "  else:\n",
        "    longitude.append(\"nan\")\n",
        "    latitude.append(\"nan\")"
      ],
      "metadata": {
        "id": "wbPWQc-cwQLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, web crawling could take too much time because the number of times the webpage can make response is limited.\n",
        "\n",
        "So instead we use keyword filtering to find the exact "
      ],
      "metadata": {
        "id": "A2uQ-9LOwlgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countryname = []\n",
        "\n",
        "start = time.time()\n",
        "for i in range(len(location)):\n",
        "  flag = False\n",
        "  if str(location[i]) != 'nan':\n",
        "    for country in pycountry.countries:\n",
        "        if country.name in location[i]:\n",
        "          flag = True\n",
        "          break\n",
        "\n",
        "  if flag:\n",
        "    countryname.append(country.name)\n",
        "  else:\n",
        "    countryname.append(\"Unknown\")\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"my_user_agent\", timeout = 10)\n",
        "longitude = []\n",
        "latitude = []\n",
        "\n",
        "country_loc_dict = {}\n",
        "for country in pycountry.countries:\n",
        "  geolo = geolocator.geocode(country.name)\n",
        "  if geolo:\n",
        "    country_loc_dict[country.name] = [geolo.longitude, geolo.latitude]\n",
        "  else:\n",
        "    country_loc_dict[country.name] = [-1,-1]\n",
        "\n",
        "country_loc_dict['Bonaire, Sint Eustatius and Saba'] = [12.1683718,-68.308183]\n",
        "country_loc_dict['Holy See (Vatican City State)'] = [41.9038795,12.4520834]\n",
        "country_loc_dict['Korea, Democratic People\\'s Republic of']=[40.3424611,127.4310054]\n",
        "country_loc_dict['Taiwan, Province of China']=[23.553118,121.0211024]\n",
        "country_loc_dict['United States Minor Outlying Islands'] = [19.295374,166.6280441]\n",
        "country_loc_dict['Virgin Islands, British'] = [18.4180894,-64.5854311]\n",
        "\n",
        "for i in range(len(countryname)):\n",
        "  if countryname[i] == 'Unknown':\n",
        "    longitude.append(float('nan'))\n",
        "    latitude.append(float('nan'))\n",
        "\n",
        "  else:\n",
        "    longitude.append(country_loc_dict[countryname[i]][0])\n",
        "    latitude.append(country_loc_dict[countryname[i]][1])\n",
        "\n",
        "new_df['country'] = countryname\n",
        "new_df['longitude'] = longitude\n",
        "new_df['latitude'] = latitude\n",
        "\n",
        "new_df.to_json('/content/drive/MyDrive/cse6740/sa_loc_df.json')"
      ],
      "metadata": {
        "id": "XnVFyaRux9tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization\n",
        "\n",
        "For visualization, we only selected a small fraction of the data which the \"country\" column is not null."
      ],
      "metadata": {
        "id": "wJjySZhgzFbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.DataFrame(loc_df, columns = ['username','date', 'content', 'country', 'label'])\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "date = new_df['date'].tolist()\n",
        "\n",
        "new_date = []\n",
        "\n",
        "for i in date:\n",
        "  i = str(i).split(\"+\")[0]\n",
        "  new_date.append(datetime.strptime(i, '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d'))\n",
        "\n",
        "new_df['Date'] = new_date\n",
        "new_df['SA'] = new_df['label'].replace({'POS':1, 'NEU': 0, 'NEG':-1})\n",
        "\n",
        "data_sample = pd.DataFrame(new_df, columns = ['username','content','country', 'Date','SA'])\n",
        "data_sample.to_csv('/content/drive/MyDrive/cse6740/sample_df.csv')"
      ],
      "metadata": {
        "id": "7UTN77NwzWPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}